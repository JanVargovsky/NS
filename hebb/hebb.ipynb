{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hebb's learning\n",
    "- Basic neuron\n",
    "  - load XML, rescale\n",
    "  - generate random values that are linearly separable in R^2 (0;1)\n",
    "- plot points\n",
    "- learn\n",
    "- plot points with neuron's line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(filename):\n",
    "    def parse_inputs(perceptron):\n",
    "        for input in perceptron.findall(\"inputDescriptions\"):\n",
    "            yield {\n",
    "                'min': float(input.find('minimum').text),\n",
    "                'max': float(input.find('maximum').text),\n",
    "                'name': input.find('name').text\n",
    "            }\n",
    "            \n",
    "    def parse_dataset_x(dataset):\n",
    "        for element in dataset.findall(\"element\"):\n",
    "            x = list(map(lambda value: float(value.text), element.find(\"inputs\").findall(\"value\")))\n",
    "            yield x\n",
    "            \n",
    "    def parse_dataset_y(dataset):\n",
    "        for element in dataset.findall(\"element\"):\n",
    "            y = float(element.find(\"output\").text)\n",
    "            yield y\n",
    "    \n",
    "    tree = ET.parse(f\"{filename}\")\n",
    "    root = tree.getroot()\n",
    "    inputs = list(parse_inputs(root.find(\"perceptron\")))\n",
    "    train_x = list(parse_dataset_x(root.find(\"TrainSet\")))\n",
    "    train_y = list(parse_dataset_y(root.find(\"TrainSet\")))\n",
    "    test = list(parse_dataset_x(root.find(\"TestSet\")))\n",
    "    \n",
    "    return (inputs, (train_x, train_y), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train(x, y):\n",
    "    x0 = list(map(lambda x: x[0], x))\n",
    "    x1 = list(map(lambda x: x[1], x))\n",
    "    \n",
    "    x0a, x1a = [], [] # 0\n",
    "    x0b, x1b = [], [] # 1\n",
    "    for xi, y in zip(x, y):\n",
    "        if y == 0:\n",
    "            x0a.append(xi[0])\n",
    "            x1a.append(xi[1])\n",
    "        else:\n",
    "            x0b.append(xi[0])\n",
    "            x1b.append(xi[1])\n",
    "    \n",
    "    plt.scatter(x0a, x1a, marker=\"o\", label=\"train 0\", c=\"r\")\n",
    "    plt.scatter(x0b, x1b, marker=\"x\", label=\"train 1\", c=\"b\")\n",
    "    \n",
    "def plot_test(x):\n",
    "    x0 = list(map(lambda x: x[0], x))\n",
    "    x1 = list(map(lambda x: x[1], x))\n",
    "    plt.scatter(x0, x1, s=100, marker=\"$?$\", label=\"test\", c=\"k\")\n",
    "    \n",
    "def plot_predicted(x, y):\n",
    "    x0 = list(map(lambda x: x[0], x))\n",
    "    x1 = list(map(lambda x: x[1], x))\n",
    "    \n",
    "    x0a, x1a = [], [] # 0\n",
    "    x0b, x1b = [], [] # 1\n",
    "    for xi, y in zip(x, y):\n",
    "        if y == 0:\n",
    "            x0a.append(xi[0])\n",
    "            x1a.append(xi[1])\n",
    "        else:\n",
    "            x0b.append(xi[0])\n",
    "            x1b.append(xi[1])\n",
    "    \n",
    "    plt.scatter(x0a, x1a, marker=\"o\", label=\"predict 0\", c=\"r\", s=100)\n",
    "    plt.scatter(x0b, x1b, marker=\"x\", label=\"predict 1\", c=\"b\", s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(inputs, dataset):    \n",
    "    result = []\n",
    "    for x in dataset:\n",
    "        record = []\n",
    "        for i, xi in enumerate(x):\n",
    "            min = inputs[i][\"min\"]\n",
    "            max = inputs[i][\"max\"]\n",
    "            record.append((xi - min) / (max - min))\n",
    "        result.append(record)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.w = np.random.rand(n + 1)\n",
    "        self.w[0] = 1\n",
    "        \n",
    "    def train(self, data_x, data_y):\n",
    "        learning_rate = 0.2\n",
    "        \n",
    "        epoch = 0\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            wrong = 0\n",
    "            for input, y_expected in zip(data_x, data_y):\n",
    "                #print(f\"input = {input}, expected output = {y_expected}\")\n",
    "                x = np.append([1], input)\n",
    "                #print(f\"x = {x}\")\n",
    "                y_real = self._predict(x)\n",
    "                #print(f\"actual output = {y_real}\")\n",
    "                delta = y_expected - y_real\n",
    "                \n",
    "                if delta != 0:\n",
    "                    wrong += 1\n",
    "\n",
    "                #print(f\"delta = {delta}\")\n",
    "                #print(f\"before = {self.w}\")\n",
    "                self.w = self.w + learning_rate * delta * x\n",
    "                #print(f\"after = {self.w}\")\n",
    "            \n",
    "            print(f\"epoch = {epoch}, score={len(data_x) - wrong}/{len(data_x)}\")\n",
    "            if wrong == 0:\n",
    "                break\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        predictions = []\n",
    "        for input in inputs:\n",
    "            x = np.append([1], input)\n",
    "            predicted = self._predict(x)\n",
    "            predictions.append(predicted)\n",
    "        return predictions\n",
    "    \n",
    "    def _predict(self, x):        \n",
    "        y = np.dot(self.w, x)\n",
    "        y = self._sign(y)\n",
    "        return y\n",
    "    \n",
    "    def _sign(self, x):\n",
    "        return 0 if x <= 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, score=2/6\n",
      "epoch = 2, score=1/6\n",
      "epoch = 3, score=6/6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.2       ,  2.40590853, -2.81865757])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron = Neuron(2)\n",
    "\n",
    "inputs, (train_x, train_y), test = parse_xml(\"obdelnik_rozsah.xml\")\n",
    "\n",
    "neuron.train(train_x, train_y)\n",
    "\n",
    "neuron.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(filename):\n",
    "    inputs, (train_x, train_y), test = parse_xml(filename)\n",
    "    \n",
    "    #print(inputs, train_x, train_y, test)\n",
    "    \n",
    "    input_dim = len(inputs)\n",
    "    \n",
    "    if input_dim == 2:\n",
    "        fig = plt.figure(figsize=(24, 8))\n",
    "        fig.suptitle(filename)\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"original\")\n",
    "        plot_train(train_x, train_y)\n",
    "        plot_test(test)\n",
    "        plt.legend()\n",
    "    \n",
    "    train_x = rescale(inputs, train_x)\n",
    "    test = rescale(inputs, test)\n",
    "    \n",
    "    if input_dim == 2:\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"rescaled\")\n",
    "        plot_train(train_x, train_y)\n",
    "        plot_test(test)\n",
    "        plt.legend()\n",
    "    \n",
    "    \n",
    "    neuron = Neuron(input_dim)\n",
    "    \n",
    "    neuron.train(train_x, train_y)\n",
    "        \n",
    "    if input_dim == 2:\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"result\")\n",
    "        plot_train(train_x, train_y)\n",
    "        plot_predicted(test, neuron.predict(test))\n",
    "        plt.legend()\n",
    "        \n",
    "        c, a, b = neuron.w\n",
    "        # ax + by + c = 0\n",
    "\n",
    "        # x = 0:\n",
    "        # by + c = 0\n",
    "        # y = -c / b\n",
    "\n",
    "        # y = 0:\n",
    "        # ax + c = 0\n",
    "        # x = -c / a\n",
    "\n",
    "        #px = -c / a\n",
    "        #py = -c / b\n",
    "        #print(f\"px=[0, {px}]\")\n",
    "        #print(f\"py=[{py}, 0]\")\n",
    "        #plt.plot([0, px], [py, 0], label=\"neuron\", color='k', linestyle='-', linewidth=2)\n",
    "        #plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "        #plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.show()\n",
    "        \n",
    "    #print(neuron.w)\n",
    "\n",
    "solve(\"obdelnik_rozsah.xml\")\n",
    "#solve(\"t2r.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"obdelnik_rozsah.xml\", \"t1r.xml\", \"t2r.xml\", \"t3r.xml\", \"t4r.xml\", \"t5r.xml\", \"t6r.xml\", \"t7r.xml\"]\n",
    "for file in files:\n",
    "    solve(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
